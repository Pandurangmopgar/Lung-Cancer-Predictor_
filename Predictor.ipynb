{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "750bd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D,Dense,MaxPooling2D,Flatten,BatchNormalization,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from joblib import load\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90939a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_str = 'E:/Lung_Cancer_CNN/Data/Data/Dataset/Train'\n",
    "val_path_str = 'E:/Lung_Cancer_CNN/Data/Data/Dataset/Valid'\n",
    "test_path_str = 'E:/Lung_Cancer_CNN/Data/Data/Dataset/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec78277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = os.listdir(test_path_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbc176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "num_classes = 4\n",
    "\n",
    "trainGenertor = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input,\n",
    "    rotation_range = 10,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range = 0.3,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    dtype = 'float32'\n",
    ")\n",
    "valGenertor = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input,\n",
    "    dtype = 'float32'\n",
    ")\n",
    "\n",
    "testGenertor = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input,\n",
    "    dtype = 'float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0effb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 613 images belonging to 4 classes.\n",
      "Found 72 images belonging to 4 classes.\n",
      "Found 315 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = trainGenertor.flow_from_directory(\n",
    "    train_path_str,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 16,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "val_data = valGenertor.flow_from_directory(\n",
    "    val_path_str,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 16,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "test_data = testGenertor.flow_from_directory(\n",
    "    test_path_str,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 16,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False\n",
    ")\n",
    "# plt.imshow(train_data)\n",
    "# for image in len(tra)\n",
    "# plotter(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e83d3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model = VGG16(\n",
    "    include_top = False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape = input_shape\n",
    ")\n",
    "for layer in VGG16_model.layers :\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a45e18af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 7, 7, 512)         2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 3, 3, 512)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              4719616   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20125892 (76.77 MB)\n",
      "Trainable params: 5410180 (20.64 MB)\n",
      "Non-trainable params: 14715712 (56.14 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.src.metrics.confusion_metrics import activations\n",
    "model = Sequential()\n",
    "model.add(VGG16_model)\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(num_classes,activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28303bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy']\n",
    ")\n",
    "callbacks = [\n",
    "    \n",
    "    tf.keras.callbacks.ModelCheckpoint('model.joblib',save_best_only=True),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17baa0c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.5268 - accuracy: 0.3948INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 77s 2s/step - loss: 1.5268 - accuracy: 0.3948 - val_loss: 1.7227 - val_accuracy: 0.4028\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 66s 2s/step - loss: 1.2566 - accuracy: 0.4796 - val_loss: 1.8345 - val_accuracy: 0.3194\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0428 - accuracy: 0.5334INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 70s 2s/step - loss: 1.0428 - accuracy: 0.5334 - val_loss: 0.9542 - val_accuracy: 0.5694\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 67s 2s/step - loss: 0.9893 - accuracy: 0.5481 - val_loss: 1.0118 - val_accuracy: 0.4861\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9753 - accuracy: 0.5612INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 70s 2s/step - loss: 0.9753 - accuracy: 0.5612 - val_loss: 0.9269 - val_accuracy: 0.5417\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9032 - accuracy: 0.5677INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 69s 2s/step - loss: 0.9032 - accuracy: 0.5677 - val_loss: 0.7980 - val_accuracy: 0.6806\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 64s 2s/step - loss: 0.8454 - accuracy: 0.6297 - val_loss: 0.9259 - val_accuracy: 0.5556\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 65s 2s/step - loss: 0.8308 - accuracy: 0.6493 - val_loss: 1.0173 - val_accuracy: 0.5556\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 65s 2s/step - loss: 0.7762 - accuracy: 0.6623 - val_loss: 0.9450 - val_accuracy: 0.6528\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7386 - accuracy: 0.6949INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 71s 2s/step - loss: 0.7386 - accuracy: 0.6949 - val_loss: 0.7203 - val_accuracy: 0.6528\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 66s 2s/step - loss: 0.6926 - accuracy: 0.7194 - val_loss: 0.9946 - val_accuracy: 0.5278\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 66s 2s/step - loss: 0.6783 - accuracy: 0.7145 - val_loss: 0.7282 - val_accuracy: 0.6528\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 63s 2s/step - loss: 0.6328 - accuracy: 0.7553 - val_loss: 0.9999 - val_accuracy: 0.6111\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 63s 2s/step - loss: 0.6085 - accuracy: 0.7520 - val_loss: 0.9590 - val_accuracy: 0.5972\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 64s 2s/step - loss: 0.5666 - accuracy: 0.7586 - val_loss: 0.7787 - val_accuracy: 0.6944\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 65s 2s/step - loss: 0.6091 - accuracy: 0.7553 - val_loss: 0.8082 - val_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 64s 2s/step - loss: 0.5911 - accuracy: 0.7439 - val_loss: 0.8033 - val_accuracy: 0.6944\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7749INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 71s 2s/step - loss: 0.5675 - accuracy: 0.7749 - val_loss: 0.7107 - val_accuracy: 0.7222\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 66s 2s/step - loss: 0.5484 - accuracy: 0.7781 - val_loss: 0.9844 - val_accuracy: 0.6806\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 65s 2s/step - loss: 0.5146 - accuracy: 0.7961 - val_loss: 0.8976 - val_accuracy: 0.7083\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.8059INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 69s 2s/step - loss: 0.5226 - accuracy: 0.8059 - val_loss: 0.6956 - val_accuracy: 0.7361\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 66s 2s/step - loss: 0.5331 - accuracy: 0.8010 - val_loss: 0.8364 - val_accuracy: 0.6389\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 65s 2s/step - loss: 0.4576 - accuracy: 0.8206 - val_loss: 0.8026 - val_accuracy: 0.7361\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 65s 2s/step - loss: 0.4621 - accuracy: 0.8238 - val_loss: 0.9746 - val_accuracy: 0.6528\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 64s 2s/step - loss: 0.4872 - accuracy: 0.8026 - val_loss: 0.8917 - val_accuracy: 0.7083\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.8026INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 70s 2s/step - loss: 0.4567 - accuracy: 0.8026 - val_loss: 0.6849 - val_accuracy: 0.8056\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 65s 2s/step - loss: 0.4583 - accuracy: 0.8206 - val_loss: 0.8259 - val_accuracy: 0.7778\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 63s 2s/step - loss: 0.4350 - accuracy: 0.8222 - val_loss: 0.7507 - val_accuracy: 0.7361\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.8418INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 67s 2s/step - loss: 0.3763 - accuracy: 0.8418 - val_loss: 0.6540 - val_accuracy: 0.8056\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.8467INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 67s 2s/step - loss: 0.4038 - accuracy: 0.8467 - val_loss: 0.5640 - val_accuracy: 0.8194\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 62s 2s/step - loss: 0.4103 - accuracy: 0.8515 - val_loss: 0.7084 - val_accuracy: 0.7222\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4253 - accuracy: 0.8336INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.joblib\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 69s 2s/step - loss: 0.4253 - accuracy: 0.8336 - val_loss: 0.5294 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.8499"
     ]
    }
   ],
   "source": [
    "results = model.fit(train_data,validation_data=val_data,epochs=100,verbose = 1,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eeeb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_data,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c368b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "predictions_prob = model.predict(test_data)\n",
    "predictions = np.argmax(predictions_prob , axis = 1)\n",
    "true_label = test_data.classes\n",
    "report = classification_report(true_label,predictions)\n",
    "print(report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85416a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(true_label,predictions)\n",
    "sns.heatmap(conf_mat ,fmt='g',annot = True , cmap='Blues' , xticklabels=test_classes , yticklabels = test_classes,)\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e347fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import joblib \n",
    "\n",
    "model_directory_path = 'E:/Lung_Cancer_CNN/Data/Data/model.joblib/'\n",
    "from tensorflow.keras.models import load_model\n",
    "'\n",
    "\n",
    "model = load_model(model_directory_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
